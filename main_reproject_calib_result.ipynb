{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4f600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23893f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT:\n",
    "directory = './calib_data_4'\n",
    "image_id = [0,1,2,3,4,5,6,7,8,9,10,12,13,14,16,17,18,19]\n",
    "\n",
    "# Camera intrinsics\n",
    "K = np.eye(3)\n",
    "K[0,0] = 1.748420877529604e+03\n",
    "K[1,1] = 1.749299610670773e+03\n",
    "K[0,2] = 7.120351208245908e+02\n",
    "K[1,2] = 4.953153651767082e+02\n",
    "\n",
    "# Camera distortion (5,)\n",
    "distortion = (-0.282673608453370, 0.197356521183472,0,0,0)\n",
    "\n",
    "# ChessBoard params\n",
    "board_size =  (11, 9)\n",
    "square_size = 0.0424 # m\n",
    "\n",
    "save_figures = False\n",
    "\n",
    "# Camera pose from end-effector frame\n",
    "camera_translation = np.array([[0.337760678839, -0.46480742266, 0.0250792296204]])\n",
    "camera_rotation = R.from_quat([-0.513693426639, 0.496370265856, 0.49749117207, 0.492176956302])\n",
    "T_camera_effector = np.eye(4)\n",
    "T_camera_effector[:3,3] = camera_translation\n",
    "T_camera_effector[:3,:3] = camera_rotation.as_matrix()\n",
    "print(T_camera_effector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a911b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation_from_rotation_translation(rotation, translation):\n",
    "    transformations = []\n",
    "    for r, t in zip(rotation,translation):\n",
    "        T = np.eye(4)\n",
    "        T[:3, :3] = r\n",
    "        T[:3, 3] = t\n",
    "        transformations.append(T)\n",
    "    return np.array(transformations)\n",
    "\n",
    "def inv(T):\n",
    "    T_inv = np.eye(4)\n",
    "    T_inv[:3,:3] = np.linalg.inv(T[:3,:3])\n",
    "    T_inv[:3,3] = -np.matmul(np.linalg.inv(T[:3,:3]), T[:3,3]) \n",
    "    return T_inv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import FancyArrowPatch\n",
    "\n",
    "class Arrow3D(FancyArrowPatch):\n",
    "    def __init__(self, xs, ys, zs, *args, **kwargs):\n",
    "        FancyArrowPatch.__init__(self, (0, 0), (0, 0), *args, **kwargs)\n",
    "        self._verts3d = xs, ys, zs\n",
    "\n",
    "    def draw(self, renderer):\n",
    "        xs3d, ys3d, zs3d = self._verts3d\n",
    "        xs, ys, zs = proj3d.proj_transform(xs3d, ys3d, zs3d, renderer.M)\n",
    "        self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))\n",
    "        FancyArrowPatch.draw(self, renderer)\n",
    "\n",
    "def insert_frame(T, scale, ax):\n",
    "    o = np.array([0,0,0,1])\n",
    "    x = np.array([scale,0,0,1])\n",
    "    y = np.array([0,scale,0,1])\n",
    "    z = np.array([0,0,scale,1])\n",
    "    o_w = np.matmul(T, o)\n",
    "    x_w = np.matmul(T, x)\n",
    "    y_w = np.matmul(T, y)\n",
    "    z_w = np.matmul(T, z)\n",
    "    # Here we create the arrows:\n",
    "    arrow_prop_dict = dict(mutation_scale=20, arrowstyle='->', shrinkA=0, shrinkB=0)\n",
    "    a = Arrow3D([o_w[0], x_w[0]], [o_w[1], x_w[1]], [o_w[2], x_w[2]], **arrow_prop_dict, color='r')\n",
    "    ax.add_artist(a)\n",
    "    a = Arrow3D([o_w[0], y_w[0]], [o_w[1], y_w[1]], [o_w[2], y_w[2]], **arrow_prop_dict, color='g')\n",
    "    ax.add_artist(a)\n",
    "    a = Arrow3D([o_w[0], z_w[0]], [o_w[1], z_w[1]], [o_w[2], z_w[2]], **arrow_prop_dict, color='b')\n",
    "    ax.add_artist(a)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9eb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-effector pose from robot base/world frame\n",
    "\n",
    "# Load invidual text files with (x,y,z,qx,qy,qz,qw) end-effector poses\n",
    "robot_pose = []\n",
    "for i in image_id:\n",
    "    filename = 'robot_pose/{}_robot_pose.txt'.format(i)\n",
    "    try:\n",
    "        robot_pose.append(np.loadtxt(os.path.join(directory, filename), delimiter=','))\n",
    "    except:\n",
    "        pass\n",
    "robot_pose = np.array(robot_pose)\n",
    "\n",
    "# Save single text file with all relevant robot poses for visp_handeye_calibrator \n",
    "np.savetxt(os.path.join(directory, 'effector2world_transform.txt'), robot_pose, delimiter=', ', fmt='%f')\n",
    "\n",
    "# Construct Nx4x4 matrix containing homogenous transformation matrices for reprojection purposes\n",
    "robot_translation = []\n",
    "robot_rotation = []\n",
    "for pose in robot_pose:\n",
    "    robot_translation.append(pose[:3])\n",
    "    r = R.from_quat(pose[3:])\n",
    "    robot_rotation.append(r.as_matrix())\n",
    "robot_translation = np.array(robot_translation)\n",
    "robot_rotation = np.array(robot_rotation)\n",
    "T_effector_world = transformation_from_rotation_translation(robot_rotation, robot_translation)\n",
    "print(T_effector_world.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3228ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern pose from camera (Extrinsics)\n",
    "# Calibration result loaded from Matlab cameraCalibrator generated script\n",
    "calib_result = scipy.io.loadmat('calib_result') \n",
    "pattern_rotation = calib_result['rotation'].transpose(2,0,1)\n",
    "pattern_translation = calib_result['translation']/1000.0\n",
    "\n",
    "# Construct Nx4x4 homogenious transformation matrices for reprojetion\n",
    "T_pattern_camera = transformation_from_rotation_translation(pattern_rotation, pattern_translation)\n",
    "print(T_pattern_camera.shape)\n",
    "\n",
    "# Convert to quaternions and save to single text file for visp_handeye_cablibrator\n",
    "for i in range(len(pattern_rotation)):\n",
    "    pattern_rotation[i] = pattern_rotation[i].T    \n",
    "r = R.from_matrix(pattern_rotation)\n",
    "quat = r.as_quat()\n",
    "object2cam_transform = np.concatenate((pattern_translation.T, quat.T), axis=0)\n",
    "np.savetxt(os.path.join(directory, 'object2cam_transform.txt'), object2cam_transform.T, delimiter=', ', fmt='%f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a557e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imagePoints = scipy.io.loadmat('imagePoints')['imagePoints']\n",
    "\n",
    "# Chess coordinates in chess frame\n",
    "point_coordinates = []\n",
    "for x in range(board_size[0]):\n",
    "    for y in range(board_size[1]):\n",
    "        point_coordinates.append([x*square_size, y*square_size, 0, 1])\n",
    "points = np.array(point_coordinates).T\n",
    "\n",
    "# Homogenious transformation matrices\n",
    "# T_cb: board in camera frame (Nx4x4)\n",
    "# T_ec: camera in end-effector frame (4x4)\n",
    "# T_we: end-effector in world frame (Nx4x4)\n",
    "\n",
    "T_cb = np.array(T_pattern_camera)\n",
    "T_ec = np.array(T_camera_effector)\n",
    "T_we = np.array(T_effector_world)\n",
    "for i in range(0,len(image_id)):\n",
    "    T_cb[i][:3,:3] = T_cb[i][:3,:3].T\n",
    "\n",
    "imgs = []\n",
    "for i in image_id:\n",
    "    imgs.append(cv2.imread(os.path.join(directory, 'images/{}.jpg'.format(i))))\n",
    "\n",
    "# Camera projection matrix: P=K[R|t]\n",
    "Rt = np.array([[1,0,0,0],\n",
    "               [0,1,0,0],\n",
    "               [0,0,1,0]])\n",
    "P = np.matmul(K,Rt)\n",
    "\n",
    "for i in range(0,len(image_id)):\n",
    "    # undistort image\n",
    "    undistorted_img = cv2.undistort(imgs[i], K, distortion, None, K)\n",
    "    undistorted_img = cv2.cvtColor(undistorted_img, cv2.COLOR_BGR2RGB)\n",
    "    # undistort points detected in chessboard\n",
    "    image_points = cv2.undistortPoints(imagePoints[:,:,i], K, distortion)\n",
    "    image_points = image_points.transpose(2,1,0).reshape(2,-1) \n",
    "    # applying necessary fix to account for undistortion\n",
    "    image_points[0] = image_points[0]*K[0,0]+K[0,2]\n",
    "    image_points[1] = image_points[1]*K[1,1]+K[1,2] \n",
    "    for j in range(0,len(image_id)):\n",
    "        # Points in j'th board frame transformed and reprojected into i'th image \n",
    "        points_j_in_camera_j = np.matmul(T_cb[j], points)\n",
    "        points_j_in_ee_j = np.matmul(T_ec, points_j_in_camera_j)\n",
    "        points_j_in_world = np.matmul(T_we[j], points_j_in_ee_j)\n",
    "        points_j_in_ee_i = np.matmul(inv(T_we[i]), points_j_in_world)\n",
    "        points_j_in_camera_i = np.matmul(inv(T_ec), points_j_in_ee_i)\n",
    "        \n",
    "        reprojection = np.matmul(P, points_j_in_camera_i)\n",
    "        reprojection[0]/=reprojection[2] \n",
    "        reprojection[1]/=reprojection[2] \n",
    "        reprojection[2]/=reprojection[2] \n",
    "        plt.figure(figsize=(15,15))\n",
    "        plt.scatter(image_points[0], image_points[1], marker='o', s=80, linewidths=1, facecolors='none', edgecolors='g')\n",
    "        plt.plot(reprojection[0],reprojection[1], 'rx', markersize=8)\n",
    "        plt.imshow(undistorted_img)\n",
    "        if save_figures:\n",
    "            plt.savefig(os.path.join(directory, 'reprojection_error/{}_{}.png'.format(i,j)))\n",
    "        plt.show()\n",
    "        \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77dbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D reprojection\n",
    "%matplotlib\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_xlim(0, 2)\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_zlabel('Z')\n",
    "ax.set_zlim(-1, 1)\n",
    "insert_frame(np.eye(4), scale=1, ax=ax) # plot world frame\n",
    "n = 20\n",
    "\n",
    "T_cbs = np.array(T_pattern_camera)\n",
    "T_ec = np.array(T_camera_effector)\n",
    "T_wes = np.array(T_effector_world)\n",
    "for i in range(0,len(image_id)):\n",
    "    T_cbs[i][:3,:3] = T_cbs[i][:3,:3].T\n",
    "    \n",
    "t = []\n",
    "for T_we, T_cb in zip(T_wes,T_cbs):\n",
    "    #insert_frame(T_we, scale=0.2, ax=ax) # plot end-effector frame \n",
    "    insert_frame(np.matmul(T_we, T_ec), scale=0.4, ax=ax) # plot camera frame\n",
    "    insert_frame(np.matmul(T_we, np.matmul(T_ec, T_cb)), scale=0.5, ax=ax) # plot camera frame\n",
    "    \n",
    "    t.append(np.matmul(T_we, np.matmul(T_camera_effector, T_cb))[:3,3])\n",
    "    pass\n",
    "print(np.std(t, axis=0))\n",
    "ax.set_title('Reprojection from measured calibration')\n",
    "ax.view_init(elev=20, azim=60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d872e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
